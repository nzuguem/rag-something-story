quarkus.langchain4j.openai.timeout=60s
quarkus.langchain4j.openai.chat-model.temperature=0
quarkus.langchain4j.openai.chat-model.model-name=gpt-4-1106-preview
quarkus.langchain4j.openai.embedding-model.model-name=text-embedding-ada-002
quarkus.langchain4j.openai.api-key=${OPENAI_API_KEY}
#quarkus.langchain4j.openai.log-requests=true
#quarkus.langchain4j.openai.log-responses=true

# Hugging Face
quarkus.langchain4j.huggingface.timeout=60s
quarkus.langchain4j.huggingface.chat-model.temperature=0
quarkus.langchain4j.huggingface.chat-model.inference-endpoint-url=https://api-inference.huggingface.co/models/tiiuae/falcon-7b-instruct
#quarkus.langchain4j.huggingface.embedding-model.inference-endpoint-url=https://api-inference.huggingface.co/pipeline/feature-extraction/sentence-transformers/all-MiniLM-L6-v2
quarkus.langchain4j.huggingface.api-key=${HUGGINGFACE_API_KEY}


# Select LLM (openai or huggingface) provider for Chat and Embedding
quarkus.langchain4j.chat-model.provider=openai
quarkus.langchain4j.embedding-model.provider=openai

# Documents sources
# In local
rag.something.story.documents.sources[0]=file://${HOME}/projets/personnels/java/quarkus/rag-something-story/src/main/resources/kevin-nzuguem-story.txt
rag.something.story.documents.sources[1]=file://${HOME}/projets/personnels/java/quarkus/rag-something-story/src/main/resources/cv-kevin-nzuguem.pdf